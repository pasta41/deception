# Hyperparameter Deception Codebase

This repository contains experimental source code of the paper:

[Hyperparameter Optimization Is Deceiving Us, and How to Stop It](https://arxiv.org/pdf/2102.03034.pdf), published at NeurIPS 2021.

[A. Feder Cooper](https://cacioepe.pe/), [Yucheng Lu](https://www.cs.cornell.edu/~yucheng/), [Jessica Zosa Forde](https://jzf2101.github.io/) and [Christopher De Sa](https://www.cs.cornell.edu/~cdesa/)

If you would like to cite our paper, please use the following bibtex:

```
@inproceedings{cooper2021hyperparameter,
  title={{Hyperparameter Optimization Is Deceiving Us, and How to Stop It}},
  author={Cooper, A Feder and Lu, Yucheng and Forde, Jessica Zosa and De Sa, Christopher},
  journal={NeurIPS},
  year={2021}
}
```

## Dependencies
* CUDA 9.2
* [PyTorch](http://pytorch.org/) version 1.6.0
* [torchvision](https://github.com/pytorch/vision/)

## Codebase Structure Overview
This codebase includes the following sections:
* [`src`](https://github.com/pasta41/deception/tree/main/src) directory, which contains all of the code we ran
* [`logs`](https://github.com/pasta41/deception/tree/main/logs) directory, which contains all of the logs generated by running the code that we included in the paper

### `src` code
This directory contains the necessary scripts and python code to run our examples illustrating hyperparameter deception:

* VGG16 trained on CIFAR-10 (replicating [Wilson et al. 2017](https://arxiv.org/pdf/1705.08292.pdf)). These are the experiments we include in the main body of the paper (Section 2, with extended results in the Supplementary Material) 
* LSTM trained on Wikitext2 (replicating [Merity et al., 2016](https://arxiv.org/pdf/1609.07843.pdf)). These are experiments that we include in the Supplementary Material.

The directory also contains the necessary scripts to run our defense (Section 5):
* Random-search-based defense to hyperparameter deception in VGG16 on CIFAR10 ([Wilson et al. 2017](https://arxiv.org/pdf/1705.08292.pdf)) 

### `logs` of the experiments we ran

This directory contains all of the experimental logs included in the paper:

* VGG16 trained on CIFAR-10, for both replicating replicating [Wilson et al. 2017](https://arxiv.org/pdf/1705.08292.pdf) and our additional tuning over Adam's epsilon parameter
* LSTM trained on Wikitext2
* Our defended-random-search HPO logs

## Replicating our Experiments, Other Examples

The runner scripts for illustrating deception are in the [`commands`](https://github.com/pasta41/deception/tree/main/src/commands) directory:
* We include two scripts for replicating our experiments from the paper: [VGG16](https://github.com/pasta41/deception/blob/main/src/commands/vgg_cifar10.sh) and [LSTM](https://github.com/pasta41/deception/blob/main/src/commands/lstm_wikitext2.sh). Combined with our `logs`, these scripts can be used to reproduce our paper's results.
* An additional example for running [Logistic Regression](https://github.com/pasta41/deception/blob/main/src/commands/logistic_regression_mnist.sh).

The runner scripts and related code for our defense expeirments are in the [`defense`](https://github.com/pasta41/deception/tree/main/src/defense) directory.

## Regenerating our Paper's Plots

We have included a Jupyter notebook containing the relevant plotting code that we used to generate the figures in the paper -- both the main paper and Supplementary Material. Please refer to the [`plot`](https://github.com/pasta41/deception/tree/main/src/plot) directory.

**Note:** The plots require installation of `seaborn` directly from GitHub, as it uses [errorbar plotting features](https://github.com/mwaskom/seaborn/issues/2403) not included in v0.11.2. A requirements file is provided, which installs the plotting code dependencies,  [`plot\requirements.txt`](https://github.com/pasta41/deception/tree/main/src/plot/requirements.txt).

## Visualization Using Tensorboard
The code will stream the metrics into the log files. If tensorboard is specified, one can run the following command to see the results:

```
tensorboard --logdir ./code/runs --port <port>
```

More info regarding the usage of tensorboard can be found [here](https://www.tensorflow.org/tensorboard/get_started).
